{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6201d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betebari\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from fuzzywuzzy import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4eb505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betebari\\AppData\\Local\\Temp\\ipykernel_7832\\910657354.py:3: DtypeWarning: Columns (7,8,9,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_svsim = pd.read_csv(\"svsim_texture_data.csv\", encoding='latin1')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVSIM_NO</th>\n",
       "      <th>SVSIM_NAME</th>\n",
       "      <th>SVSIM_ID</th>\n",
       "      <th>SVSIM_PT</th>\n",
       "      <th>SVSIM_PC</th>\n",
       "      <th>SSURGO</th>\n",
       "      <th>SWN</th>\n",
       "      <th>Local_ID</th>\n",
       "      <th>CASGEM_MSC</th>\n",
       "      <th>WCR_NO</th>\n",
       "      <th>UTMX</th>\n",
       "      <th>UTMY</th>\n",
       "      <th>Z</th>\n",
       "      <th>INTERVALSTART</th>\n",
       "      <th>INTERVALEND</th>\n",
       "      <th>USCS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>2051666.852</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rocky Clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>2051666.852</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>2051666.852</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>2051666.852</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>2051666.852</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVSIM_NO SVSIM_NAME     SVSIM_ID  SVSIM_PT  SVSIM_PC  SSURGO       SWN  \\\n",
       "0       1.0  00014CVHM  00014CVHM-1       1.0       0.0     NaN  13N04E08   \n",
       "1       1.0  00014CVHM  00014CVHM-2       2.0       0.0     NaN  13N04E08   \n",
       "2       1.0  00014CVHM  00014CVHM-3       3.0       0.0     NaN  13N04E08   \n",
       "3       1.0  00014CVHM  00014CVHM-4       4.0       0.0     NaN  13N04E08   \n",
       "4       1.0  00014CVHM  00014CVHM-5       5.0       0.0     NaN  13N04E08   \n",
       "\n",
       "  Local_ID CASGEM_MSC WCR_NO         UTMX         UTMY    Z    INTERVALSTART  \\\n",
       "0      NaN        NaN  48251  2051666.852  14162175.46  42.12            0.0   \n",
       "1      NaN        NaN  48251  2051666.852  14162175.46  42.12           16.0   \n",
       "2      NaN        NaN  48251  2051666.852  14162175.46  42.12           44.0   \n",
       "3      NaN        NaN  48251  2051666.852  14162175.46  42.12           50.0   \n",
       "4      NaN        NaN  48251  2051666.852  14162175.46  42.12           60.0   \n",
       "\n",
       "   INTERVALEND USCS DESCRIPTION  \n",
       "0         16.0  NaN  Rocky Clay  \n",
       "1         44.0  NaN        Clay  \n",
       "2         50.0  NaN        Clay  \n",
       "3         60.0  NaN        Clay  \n",
       "4         70.0  NaN        Clay  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with 'latin1' encoding\n",
    "try:\n",
    "    df_svsim = pd.read_csv(\"svsim_texture_data.csv\", encoding='latin1')\n",
    "except UnicodeDecodeError:\n",
    "    # If 'latin1' fails, try with 'cp1252' encoding\n",
    "    df_svsim = pd.read_csv(\"svsim_texture_data.csv\", encoding='cp1252')\n",
    "\n",
    "# Assuming df4 is the DataFrame where you want to rename the column\n",
    "df_svsim.rename(columns={'X': 'UTMX','Y': 'UTMY', 'TOP_BGS':'INTERVALSTART',\n",
    "              'BASE_BGS':'INTERVALEND', 'LITH_DESC': 'DESCRIPTION' }, inplace=True)\n",
    "\n",
    "# Display the first few rows to confirm the renaming\n",
    "df_svsim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d7356f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the 'DESCRIPTION' column exists\n",
    "if 'DESCRIPTION' not in df_svsim.columns:\n",
    "    raise KeyError(\"The 'DESCRIPTION' column does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6be014-8b47-4b25-bf66-ed07ca8cc2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace typos in the 'DESCRIPTION' column of the DataFrame\n",
    "df_svsim['DESCRIPTION'] = df_svsim['DESCRIPTION'].replace({\n",
    "    'mudstrone': 'mudstone',\n",
    "    'sandsttone': 'sandstone',\n",
    "    'Hard Pan': 'hardpan'\n",
    "}, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dc9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the USCS codes and known USCS names globally\n",
    "uscs_keywords_keep = [\n",
    "    '(ML)', '(GP)', '(SP-SM)', '(GC)', '(CL)', '(CH)', '(MH)', '(GP-GM)', '(CL/ML)', '(GW/GM)',\n",
    "    '(GP-GC)', '(ML-SM)', '(SP-SM)', '(SC-SM)', '(SC)', '(SW/GW)', '(SM/GM)', '(GP-SP)',\n",
    "    '(CL/SM)', '(ML/GW)', '(SP & GP)', '(GW/GC)', '(GW-GM/GW)', '(SP-SC)','(SP/SM)', '(SM/SW)','(SP/GP/COBL)',\n",
    "]\n",
    "\n",
    "# Function to extract USCS codes from text within parentheses and direct codes\n",
    "def extract_uscs(text):\n",
    "    if isinstance(text, str):\n",
    "        text_upper = text.upper()  # Convert text to uppercase for case insensitivity\n",
    "\n",
    "        # Check for USCS code within parentheses\n",
    "        match = re.search(r'\\((.*?)\\)', text_upper)\n",
    "        if match:\n",
    "            code_in_parentheses = f\"({match.group(1).strip()})\"\n",
    "            if code_in_parentheses in uscs_codes:\n",
    "                cleaned_text = text[:match.start()].strip() + \" \" + text[match.end():].strip()\n",
    "                return code_in_parentheses, cleaned_text.strip()\n",
    "\n",
    "        # Check if the text itself is a valid USCS code\n",
    "        if text_upper in uscs_keywords_keep:\n",
    "            return text_upper, text\n",
    "\n",
    "    return 'unknown', text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b322bcfc-a530-440e-aaa9-4d661bfa3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to convert inaccurate USCS \n",
    "USCS_conversions = {\n",
    "    'SHLE': [ 'shale'],\n",
    "    'CLSN':['claystone','mudstone'],\n",
    "    'STST':['slst','siltstone'],\n",
    "    'TPSL':['topsoil', 'soil/organic','tp'],\n",
    "    'VFRG':['volcanic frags'],\n",
    "    'CONG':['conglomerate'],\n",
    "    'COBL':['cobbles'],\n",
    "    'SDST':['sandstone'],\n",
    "    'TUFF':['tuff'],\n",
    "    'ASH':['ash'],\n",
    "    'GW/SW':['other-fine'],\n",
    "    'CH/ML':['other-coarse'],\n",
    "    'FRAC':['FRCT'],\n",
    "}\n",
    "\n",
    "# Define a function to apply USCS conversions (case-insensitive)\n",
    "def convert_uscs(uscs_value, conversions):\n",
    "    # Ensure the value is a string\n",
    "    if isinstance(uscs_value, str):  \n",
    "        uscs_value_lower = uscs_value.lower()  # Convert the USCS value to lowercase\n",
    "        for key, values in conversions.items():\n",
    "            # Check if the USCS value matches any of the dictionary values (case-insensitive)\n",
    "            if uscs_value_lower in [v.lower() for v in values]:\n",
    "                return key  # Return the correct USCS classification\n",
    "    return uscs_value  # If no match, return the original value\n",
    "\n",
    "# Apply the conversion function to the 'USCS' column in the df_svsim DataFrame\n",
    "df_svsim['USCS'] = df_svsim['USCS'].apply(lambda x: convert_uscs(x, USCS_conversions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2e05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define qualifiers\n",
    "color_qualifiers = ['red', 'green', 'black', 'brown', 'gray', 'grayish', 'white','greenish',\n",
    "                    'reddish', 'yellow', 'dark', 'light', 'tan', 'colored', 'blue','brownblack',\n",
    "                   'yellowish','purple', 'orange','brw.','grey','(blue)', 'red,'  ]\n",
    "\n",
    "texture_qualifiers = ['loose', 'hard', 'coarse', 'fine', 'compacted', 'cemented','crushed',\n",
    "           'salt & pepper','Minor','medium', 'large','firm', 'small', 'fracture', 'frac','little',\n",
    "           'fractured', 'soft', 'minor', 'eroded','tight','broken', 'brittle','chunky', 'crusty',\n",
    "           'med.','packed', 'brittle', 'porous', 'pea', 'welded', 'mixed', 'softer', 'joint',\n",
    "           'chunky','large', 'big','solid','firm','hard','heavy','very stiff', '(solid)', '(cement)',\n",
    "           'laminated','poorly graded', 'well graded', 'sticky', 'grained','graded', 'med','dry' ,   \n",
    "            '(cemented)', '(set)', '(water)','soft-med' ,'stiff' ,'crumbly' , 'granulated' ,'streaky',       \n",
    "            'tough' ,'(varied)' ,  'gritty','holey', 'impervious' ,  'rubbery', 'rough','stringers',      \n",
    "             'ashy', 'porous', '(balls)' ,'(tough)', '(hard drilling)','mottled', 'poorly',\n",
    "             'no cementation', 'is grained', 'subrounded', 'no staining', 'no odor','with holes'       \n",
    "              , '( water)' , 'water']\n",
    "\n",
    "# Copy data from 'DESCRIPTION' to a new column 'TEXTURE'\n",
    "df_svsim['TEXTURE'] = df_svsim['DESCRIPTION']\n",
    "\n",
    "# Function to extract qualifiers from a string\n",
    "def extract_qualifiers(description, qualifiers):\n",
    "    if pd.isna(description):\n",
    "        return []\n",
    "    words = description.lower().split()\n",
    "    return [word for word in words if word in qualifiers]\n",
    "\n",
    "# Extract COLORQUALIFIER and TEXTUREQUALIFIER\n",
    "df_svsim['COLORQUALIFIER_EXTRACTED'] = df_svsim.apply(lambda row: extract_qualifiers(row['TEXTURE'], color_qualifiers), axis=1)\n",
    "df_svsim['TEXTUREQUALIFIER_EXTRACTED'] = df_svsim.apply(lambda row: extract_qualifiers(row['TEXTURE'], texture_qualifiers), axis=1)\n",
    "\n",
    "# Convert lists to strings\n",
    "df_svsim['COLORQUALIFIER_EXTRACTED'] = df_svsim['COLORQUALIFIER_EXTRACTED'].apply(lambda x: ' '.join(x) if x else np.nan)\n",
    "df_svsim['TEXTUREQUALIFIER_EXTRACTED'] = df_svsim['TEXTUREQUALIFIER_EXTRACTED'].apply(lambda x: ' '.join(x) if x else np.nan)\n",
    "\n",
    "# Function to remove qualifiers from a string\n",
    "def remove_qualifiers(description, qualifiers):\n",
    "    if pd.isna(description):\n",
    "        return description\n",
    "    words = description.lower().split()\n",
    "    return ' '.join([word for word in words if word not in qualifiers])\n",
    "\n",
    "# Create DESCRIPTION2 column\n",
    "df_svsim['NEW_DESCRIPTION'] = df_svsim.apply(lambda row: remove_qualifiers(row['TEXTURE'], color_qualifiers + texture_qualifiers), axis=1)\n",
    "\n",
    "# Handle missing 'TEXTUREMODIFIER1' column\n",
    "if 'TEXTUREMODIFIER1' not in df_svsim.columns:\n",
    "    df_svsim['TEXTUREMODIFIER1'] = np.nan\n",
    "\n",
    "# Concatenate TEXTUREMODIFIER1 and DESCRIPTION if they are not equal, and include new columns\n",
    "df_svsim['TEXTURE_MODIFIED'] = df_svsim.apply(\n",
    "    lambda row: (row['TEXTUREMODIFIER1'] + ' ' if pd.notna(row['TEXTUREMODIFIER1']) and row['TEXTUREMODIFIER1'] != row['TEXTURE'] else '') + (row['DESCRIPTION'] if pd.notna(row['DESCRIPTION']) else ''),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Update original COLORQUALIFIER and TEXTUREQUALIFIER columns\n",
    "df_svsim['COLORQUALIFIER'] = df_svsim['COLORQUALIFIER_EXTRACTED']\n",
    "df_svsim['TEXTUREQUALIFIER'] = df_svsim['TEXTUREQUALIFIER_EXTRACTED']\n",
    "\n",
    "# Drop the intermediate columns if needed\n",
    "df_svsim.drop(columns=['COLORQUALIFIER_EXTRACTED', 'TEXTUREQUALIFIER_EXTRACTED','TEXTURE','TEXTUREMODIFIER1','TEXTURE_MODIFIED',],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c26193f-bb5c-4745-afc6-93e00751ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_keep = {\n",
    "    # Compound soil types\n",
    "    'gravelly clay', 'sandy loam', 'silty clay', 'pebbly loam', 'cobbly sand', 'sandy mud',\n",
    "    'clayey loam', 'sandy clay', 'silty loam', 'gravelly sand', 'pebbley sand','clayey wood',\n",
    "    'cobbley clay', 'loamy sand', 'clayey gravel', 'gravelly loam', 'pebbley clay','gravelly wood',\n",
    "    'sandy gravel', 'clayey sand', 'silty gravel', 'loamy gravel', 'silty sand','mucky mud',\n",
    "    'gravelly silt', 'pebbley gravel', 'cobbley loam', 'clayey silt', 'gravelly clayey sand',\n",
    "    'loamy clay', 'pebbley loamy', 'sandy silty', 'cobbley gravel', 'clayey sandy','cobbley sandy pebbles',\n",
    "    'silty cobbly', 'gravelly pebbly', 'sandy cobble', 'gravelly sandy','gravelly cobbles','cobbley sandy pebbles',\n",
    "    'rocky clay', 'rocky loam', 'rocky gravel', 'rocky silt','rocky sand','gravelly boulders','cobbley gravelly wood',\n",
    "    'cobbley gravelly pebbles',\n",
    "    # Sedimentary rocks\n",
    "    'sandstone', 'conglomerate', 'shale', 'siltstone', 'limestone', 'cobblestone',  'mudstone', \n",
    "    \n",
    "    # Soil classifications\n",
    "    'silt', 'sand', 'gravel',  'clay', 'boulder', 'loam', 'cobble', 'gravels','cobbles','boulders','clays','mud', 'wood',\n",
    "    'pebbles',\n",
    "\n",
    "    # Soil descriptors\n",
    "    'sticky clay', 'fat clay', 'lean clay', 'hardpan','pan', 'organic', 'adobe',  'weathered','poorly graded sand', 'well graded sand',\n",
    "    'poorly graded gravel', 'well graded gravel',\n",
    "    # Rocks and minerals\n",
    "    'basalt', 'basaltic', 'pumice', 'latite', 'volcanics', 'volcanic', 'cinder', 'ash', 'lime',\n",
    "    'tufa', 'tuff', 'lava', 'rhyolite', 'granite', 'diorite', 'quartz', 'gabbro', 'quartzite', \n",
    "    'granodiorite', 'igneous', 'andesite', 'greenstone', 'slate', 'schist', 'serpentine', \n",
    "    'metasediment', 'phyllite', 'argillite', 'bluestone', 'soapstone', 'chert','fractured',\n",
    "    'fractured rock', 'gouge', 'hardrock', 'rock','bedrock','frac','tuscan','lapilli','limestone',\n",
    "\n",
    "    # Other geological terms\n",
    "    'sediment', 'alluvium', 'loam', 'peat', 'organics','topsoil','soil', 'organic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16413b19-2340-49d8-b6ec-dacd580406b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVSIM_NO</th>\n",
       "      <th>SVSIM_NAME</th>\n",
       "      <th>SVSIM_ID</th>\n",
       "      <th>SVSIM_PT</th>\n",
       "      <th>SVSIM_PC</th>\n",
       "      <th>SSURGO</th>\n",
       "      <th>SWN</th>\n",
       "      <th>Local_ID</th>\n",
       "      <th>CASGEM_MSC</th>\n",
       "      <th>WCR_NO</th>\n",
       "      <th>...</th>\n",
       "      <th>UTMY</th>\n",
       "      <th>Z</th>\n",
       "      <th>INTERVALSTART</th>\n",
       "      <th>INTERVALEND</th>\n",
       "      <th>USCS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>NEW_DESCRIPTION</th>\n",
       "      <th>COLORQUALIFIER</th>\n",
       "      <th>TEXTUREQUALIFIER</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rocky Clay</td>\n",
       "      <td>rocky clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rocky clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVSIM_NO SVSIM_NAME     SVSIM_ID  SVSIM_PT  SVSIM_PC  SSURGO       SWN  \\\n",
       "0       1.0  00014CVHM  00014CVHM-1       1.0       0.0     NaN  13N04E08   \n",
       "1       1.0  00014CVHM  00014CVHM-2       2.0       0.0     NaN  13N04E08   \n",
       "2       1.0  00014CVHM  00014CVHM-3       3.0       0.0     NaN  13N04E08   \n",
       "3       1.0  00014CVHM  00014CVHM-4       4.0       0.0     NaN  13N04E08   \n",
       "4       1.0  00014CVHM  00014CVHM-5       5.0       0.0     NaN  13N04E08   \n",
       "\n",
       "  Local_ID CASGEM_MSC WCR_NO  ...         UTMY    Z    INTERVALSTART  \\\n",
       "0      NaN        NaN  48251  ...  14162175.46  42.12            0.0   \n",
       "1      NaN        NaN  48251  ...  14162175.46  42.12           16.0   \n",
       "2      NaN        NaN  48251  ...  14162175.46  42.12           44.0   \n",
       "3      NaN        NaN  48251  ...  14162175.46  42.12           50.0   \n",
       "4      NaN        NaN  48251  ...  14162175.46  42.12           60.0   \n",
       "\n",
       "   INTERVALEND  USCS DESCRIPTION NEW_DESCRIPTION COLORQUALIFIER  \\\n",
       "0         16.0   NaN  Rocky Clay      rocky clay            NaN   \n",
       "1         44.0   NaN        Clay            clay            NaN   \n",
       "2         50.0   NaN        Clay            clay            NaN   \n",
       "3         60.0   NaN        Clay            clay            NaN   \n",
       "4         70.0   NaN        Clay            clay            NaN   \n",
       "\n",
       "  TEXTUREQUALIFIER    KEYWORDS  \n",
       "0              NaN  rocky clay  \n",
       "1              NaN        clay  \n",
       "2              NaN        clay  \n",
       "3              NaN        clay  \n",
       "4              NaN        clay  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the key words to convert into USCS\n",
    "descrip = df_svsim['DESCRIPTION']\n",
    "\n",
    "# Build the regex pattern\n",
    "pattern = r'\\b(?:' + '|'.join(map(re.escape, keywords_keep)) + r')\\b'\n",
    "\n",
    "# Apply the regex, handling NaN values by converting them to an empty string\n",
    "extracted_words = [re.findall(pattern, str(d), re.IGNORECASE) for d in descrip]\n",
    "\n",
    "# Add the extracted words as a new column\n",
    "df_svsim['KEYWORDS_LIST'] = extracted_words\n",
    "\n",
    "# Join the keywords into a single string\n",
    "new_descriptions = df_svsim['KEYWORDS_LIST']\n",
    "separator = ' ,'\n",
    "d = []\n",
    "\n",
    "for new_description in new_descriptions:\n",
    "    new_descrip = separator.join(new_description)\n",
    "    d.append(new_descrip.lower())\n",
    "\n",
    "# Add the final keywords column\n",
    "df_svsim['KEYWORDS'] = d\n",
    "\n",
    "# Drop the intermediate column\n",
    "df_svsim = df_svsim.drop(['KEYWORDS_LIST'], axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_svsim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8ad452",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_mapping = {\n",
    "    # USCS Soil Classifications\n",
    "    'CH': ['clay','clays', 'adobe clay', 'sticky clay', 'fat clay', 'adobe'],\n",
    "    'CH-SC': ['clay sand'],\n",
    "    'SC-GP': ['gravelly clayey sand'],\n",
    "    'CL': ['lean clay', 'silty clay', 'sandy clay', 'gravelly clay',],\n",
    "    'OH': ['organic clay'], \n",
    "    'TPSL': ['soil', 'top soil', 'topsoil', 'silty soil'],\n",
    "    'GP': ['poorly graded gravel', 'gravel','cobbley gravelly pebbles','gravels'],\n",
    "    'COBL': ['cobble', 'boulder','cobbles', 'boulders', 'pebbles'],\n",
    "    'GW': ['well graded gravel', 'alluvium', 'pebbles', 'pebbley gravel', 'gravely cobbles', 'decomposed granite'],\n",
    "    'SP': ['poorly graded sand', 'sand'],\n",
    "    'SP-GP': ['gravelly sand', 'sandy gravel','sediment'],\n",
    "    'SW': ['well graded sand', 'sandy'],\n",
    "    'SW-GW': ['pebbley sand'],\n",
    "    'SM-SC': ['sandy shale and sand'],\n",
    "    'SM': ['silty sand'],\n",
    "    'SC': ['clayey sand'],\n",
    "    'ML': ['loam', 'clayey loam', 'hardpan','pan','silt', 'sandy silt', 'clayey silt', 'sandy shale'],\n",
    "    'PT': ['muck', 'peat', 'organics', 'mud', 'mucky mud', 'wood'],\n",
    "    'CL-PT': ['woody clay'],\n",
    "    'GC': ['gravelly clayey'],\n",
    "    'GM':['silty pebbles'],\n",
    "\n",
    "    # Volcanic and Igneous Rocks\n",
    "    'BSLT': ['basalt','andesite','latite', 'basaltic',],\n",
    "    'VOLC': [ 'volcanics','volcanic'],\n",
    "    'ASH': ['ash'],\n",
    "    'LAVA': ['lava' ],\n",
    "    'TUFF': ['tuff'],\n",
    "    'VFRG': ['pumice'],    \n",
    "    'IGNS': ['diorite', 'gabbro' ],\n",
    "    'GRNT': ['granite', 'quartzite', 'granodiorite','quartz'],\n",
    "    \n",
    "    # Metamorphic Rocks\n",
    "    'SCHT': ['slate', 'schist'],\n",
    "    'META': ['greenstone',  'serpentine', 'phyllite', 'argillite', 'soapstone'],\n",
    "\n",
    "    # Sedimentary Rocks\n",
    "    'SDST': ['sandstone'],\n",
    "    'CONG': ['conglomerate', 'cobblestone'],\n",
    "    'SHLE': ['shale'], \n",
    "    'STST': ['siltstone'],\n",
    "    'CLSN': ['mudstone'],\n",
    "    'LMST': ['limestone','lime'],\n",
    "    'LMST-CL': ['clayey lime'],\n",
    "\n",
    "    # Double Porosity Rocks (fractured rocks)\n",
    "    'FRAC': ['fractured', 'fracture', 'fractured rock'],\n",
    "\n",
    "    # Miscellaneous Classifications\n",
    "    'GP-OH': ['dirty gravel'],\n",
    "    'SP-OH': ['dirty sand'],\n",
    "    'OH': ['dirty top soil','mucky mud', 'organic'],\n",
    "    'CL-GRNT': ['granitic clay'],\n",
    "    'SP-GRNT': ['granitic sand'],\n",
    "    'ROCK': ['rock' , 'chert','bedrock',],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4a978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVSIM_NO</th>\n",
       "      <th>SVSIM_NAME</th>\n",
       "      <th>SVSIM_ID</th>\n",
       "      <th>SVSIM_PT</th>\n",
       "      <th>SVSIM_PC</th>\n",
       "      <th>SSURGO</th>\n",
       "      <th>SWN</th>\n",
       "      <th>Local_ID</th>\n",
       "      <th>CASGEM_MSC</th>\n",
       "      <th>WCR_NO</th>\n",
       "      <th>...</th>\n",
       "      <th>UTMY</th>\n",
       "      <th>Z</th>\n",
       "      <th>INTERVALSTART</th>\n",
       "      <th>INTERVALEND</th>\n",
       "      <th>USCS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>NEW_DESCRIPTION</th>\n",
       "      <th>COLORQUALIFIER</th>\n",
       "      <th>TEXTUREQUALIFIER</th>\n",
       "      <th>KEYWORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>CH</td>\n",
       "      <td>Rocky Clay</td>\n",
       "      <td>rocky clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rocky clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>CH</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>CH</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>CH</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>14162175.46</td>\n",
       "      <td>42.12</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>CH</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVSIM_NO SVSIM_NAME     SVSIM_ID  SVSIM_PT  SVSIM_PC  SSURGO       SWN  \\\n",
       "0       1.0  00014CVHM  00014CVHM-1       1.0       0.0     NaN  13N04E08   \n",
       "1       1.0  00014CVHM  00014CVHM-2       2.0       0.0     NaN  13N04E08   \n",
       "2       1.0  00014CVHM  00014CVHM-3       3.0       0.0     NaN  13N04E08   \n",
       "3       1.0  00014CVHM  00014CVHM-4       4.0       0.0     NaN  13N04E08   \n",
       "4       1.0  00014CVHM  00014CVHM-5       5.0       0.0     NaN  13N04E08   \n",
       "\n",
       "  Local_ID CASGEM_MSC WCR_NO  ...         UTMY    Z    INTERVALSTART  \\\n",
       "0      NaN        NaN  48251  ...  14162175.46  42.12            0.0   \n",
       "1      NaN        NaN  48251  ...  14162175.46  42.12           16.0   \n",
       "2      NaN        NaN  48251  ...  14162175.46  42.12           44.0   \n",
       "3      NaN        NaN  48251  ...  14162175.46  42.12           50.0   \n",
       "4      NaN        NaN  48251  ...  14162175.46  42.12           60.0   \n",
       "\n",
       "   INTERVALEND  USCS DESCRIPTION NEW_DESCRIPTION COLORQUALIFIER  \\\n",
       "0         16.0    CH  Rocky Clay      rocky clay            NaN   \n",
       "1         44.0    CH        Clay            clay            NaN   \n",
       "2         50.0    CH        Clay            clay            NaN   \n",
       "3         60.0    CH        Clay            clay            NaN   \n",
       "4         70.0    CH        Clay            clay            NaN   \n",
       "\n",
       "  TEXTUREQUALIFIER    KEYWORDS  \n",
       "0              NaN  rocky clay  \n",
       "1              NaN        clay  \n",
       "2              NaN        clay  \n",
       "3              NaN        clay  \n",
       "4              NaN        clay  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updated function to extract USCS codes from text within parentheses and direct codes\n",
    "def extract_uscs(text, current_uscs):\n",
    "    # If there is already a value in the USCS column, return it\n",
    "    if isinstance(current_uscs, str) and current_uscs.lower() != 'unknown':\n",
    "        return current_uscs\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # Convert text to lower case\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\- ,%]', '', text)  # Allow hyphens, commas, and percentages\n",
    "\n",
    "        # Check if the cleaned text is empty\n",
    "        if not text.strip():\n",
    "            return 'unknown'  # If the cleaned text is empty, return 'unknown'\n",
    "\n",
    "        # Tokenize the text into individual words or phrases\n",
    "        tokens = text.split()\n",
    "\n",
    "        # Track all matches\n",
    "        matched_soils = []\n",
    "\n",
    "        # Check for exact matches in the dictionary for each token\n",
    "        for token in tokens:\n",
    "            for key, synonyms in classification_mapping.items():\n",
    "                if token in synonyms:\n",
    "                    matched_soils.append(key.upper())\n",
    "\n",
    "        # If we have any exact matches, return them (multiple can be combined)\n",
    "        if matched_soils:\n",
    "            return ','.join(set(matched_soils))  # Remove duplicates and join\n",
    "\n",
    "        # If no exact match is found, try using rapidfuzz for approximate matching\n",
    "        for token in tokens:\n",
    "            best_match = process.extractOne(token, classification_mapping.keys(), scorer=fuzz.token_sort_ratio)\n",
    "            if best_match and best_match[1] > 75:  # Threshold can be adjusted\n",
    "                matched_soils.append(best_match[0].upper())\n",
    "\n",
    "        # Return the closest matches found using rapidfuzz, if any\n",
    "        if matched_soils:\n",
    "            return ','.join(set(matched_soils))  # Remove duplicates and join\n",
    "\n",
    "        # Check for USCS code within parentheses (if provided)\n",
    "        match = re.search(r'\\((.*?)\\)', text)\n",
    "        if match:\n",
    "            return match.group(1).upper()\n",
    "\n",
    "    return 'unknown'\n",
    "\n",
    "# Applying the extract_uscs function to the DataFrame\n",
    "df_svsim['USCS'] = df_svsim.apply(lambda row: extract_uscs(row['KEYWORDS'], row['USCS']), axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df_svsim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eefe3d03-e5ab-45f1-ab1b-99a861392560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched 'USCS' values: ['unknown' 'ss' 'hp' 'vlss' 'nr' 'fill']\n",
      "Number of unique WCRNUMBER values: 4691\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVSIM_NO</th>\n",
       "      <th>WCRNUMBER</th>\n",
       "      <th>SVSIM_ID</th>\n",
       "      <th>SVSIM_PT</th>\n",
       "      <th>SVSIM_PC</th>\n",
       "      <th>SSURGO</th>\n",
       "      <th>SWN</th>\n",
       "      <th>Local_ID</th>\n",
       "      <th>CASGEM_MSC</th>\n",
       "      <th>WCR_NO</th>\n",
       "      <th>...</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>NEW_DESCRIPTION</th>\n",
       "      <th>COLORQUALIFIER</th>\n",
       "      <th>TEXTUREQUALIFIER</th>\n",
       "      <th>KEYWORDS</th>\n",
       "      <th>HydraulicConductivity</th>\n",
       "      <th>AverageCoarseFraction</th>\n",
       "      <th>Avg Specific Yield (%)</th>\n",
       "      <th>Avg Ss (1/L)</th>\n",
       "      <th>Avg Kv (ft/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>Rocky Clay</td>\n",
       "      <td>rocky clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rocky clay</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00349</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00349</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00349</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00349</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>00014CVHM</td>\n",
       "      <td>00014CVHM-5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13N04E08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48251</td>\n",
       "      <td>...</td>\n",
       "      <td>Clay</td>\n",
       "      <td>clay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clay</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00349</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVSIM_NO  WCRNUMBER     SVSIM_ID  SVSIM_PT  SVSIM_PC  SSURGO       SWN  \\\n",
       "0       1.0  00014CVHM  00014CVHM-1       1.0       0.0     NaN  13N04E08   \n",
       "1       1.0  00014CVHM  00014CVHM-2       2.0       0.0     NaN  13N04E08   \n",
       "2       1.0  00014CVHM  00014CVHM-3       3.0       0.0     NaN  13N04E08   \n",
       "3       1.0  00014CVHM  00014CVHM-4       4.0       0.0     NaN  13N04E08   \n",
       "4       1.0  00014CVHM  00014CVHM-5       5.0       0.0     NaN  13N04E08   \n",
       "\n",
       "  Local_ID CASGEM_MSC WCR_NO  ...  DESCRIPTION  NEW_DESCRIPTION  \\\n",
       "0      NaN        NaN  48251  ...   Rocky Clay       rocky clay   \n",
       "1      NaN        NaN  48251  ...         Clay             clay   \n",
       "2      NaN        NaN  48251  ...         Clay             clay   \n",
       "3      NaN        NaN  48251  ...         Clay             clay   \n",
       "4      NaN        NaN  48251  ...         Clay             clay   \n",
       "\n",
       "   COLORQUALIFIER  TEXTUREQUALIFIER    KEYWORDS HydraulicConductivity  \\\n",
       "0             NaN               NaN  rocky clay              0.016402   \n",
       "1             NaN               NaN        clay              0.016402   \n",
       "2             NaN               NaN        clay              0.016402   \n",
       "3             NaN               NaN        clay              0.016402   \n",
       "4             NaN               NaN        clay              0.016402   \n",
       "\n",
       "  AverageCoarseFraction Avg Specific Yield (%) Avg Ss (1/L) Avg Kv (ft/day)  \n",
       "0                   2.5                    2.0      0.00349          0.0005  \n",
       "1                   2.5                    2.0      0.00349          0.0005  \n",
       "2                   2.5                    2.0      0.00349          0.0005  \n",
       "3                   2.5                    2.0      0.00349          0.0005  \n",
       "4                   2.5                    2.0      0.00349          0.0005  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the provided Excel file\n",
    "file_path = r'C:\\Users\\betebari\\Documents\\C2VSim_Texture\\OSWCR\\USCS-averageKxy-CoarseFractions.xlsx'\n",
    "excel_data = pd.read_excel(file_path)\n",
    "\n",
    "# Strip any leading/trailing spaces from 'Sediment/Rock Type' column in the Excel data\n",
    "excel_data['Sediment/Rock Type'] = excel_data['Sediment/Rock Type'].str.strip()\n",
    "\n",
    "# Convert 'Sediment/Rock Type' to lowercase for case-insensitive matching\n",
    "excel_data['Sediment/Rock Type'] = excel_data['Sediment/Rock Type'].str.lower()\n",
    "\n",
    "# Create a dictionary mapping Soil Classification to Average Hydraulic Conductivity (case-insensitive)\n",
    "hydraulic_conductivity_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Average Hydraulic Conductivity (ft/day)']))\n",
    "\n",
    "# Create a dictionary mapping Soil Classification to Average Coarse Fraction (case-insensitive)\n",
    "coarse_fraction_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Average Coarse Fraction (%)']))\n",
    "\n",
    "# Create separate mappings for Specific Yield, Ss, and Kv based on the Excel data columns\n",
    "specific_yield_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Avg Specific Yield (%)']))\n",
    "ss_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Avg Ss (1/L)']))\n",
    "kv_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Avg Kv (ft/day)']))\n",
    "\n",
    "# Convert 'USCS' column to lowercase for case-insensitive matching\n",
    "df_svsim['USCS'] = df_svsim['USCS'].str.lower()\n",
    "\n",
    "# Function to handle the slash (50/50) and dash (sequential rule) logic\n",
    "def aggregate_uscs_values(uscs_value, mapping, agg_func='average'):\n",
    "    # Split USCS string into parts by commas, slashes, and dashes\n",
    "    if '/' in uscs_value:\n",
    "        # For slash, treat as 50/50\n",
    "        uscs_list = [item.strip().lower() for item in uscs_value.split('/')]\n",
    "        values = [mapping.get(uscs) for uscs in uscs_list if uscs in mapping]\n",
    "        # Take the average for 50/50 mixtures\n",
    "        if values:\n",
    "            return sum(values) / len(values)\n",
    "    elif '-' in uscs_value:\n",
    "        # For dash, follow the first one that matches\n",
    "        uscs_list = [item.strip().lower() for item in uscs_value.split('-')]\n",
    "        for uscs in uscs_list:\n",
    "            if uscs in mapping:\n",
    "                return mapping.get(uscs)  # Return the first match\n",
    "    else:\n",
    "        # If no special characters, treat as a single or comma-separated list\n",
    "        uscs_list = [item.strip().lower() for item in uscs_value.split(',')]\n",
    "        values = [mapping.get(uscs) for uscs in uscs_list if uscs in mapping]\n",
    "\n",
    "    # Apply 12% coarse fraction if secondary USCS classification is present and no match found\n",
    "    if 'gc' in uscs_list or 'sc' in uscs_list or 'gm' in uscs_list or 'sm' in uscs_list:\n",
    "        return 12 if not values else sum(values) / len(values)\n",
    "\n",
    "    if values:\n",
    "        if agg_func == 'average':\n",
    "            return sum(values) / len(values)\n",
    "        elif agg_func == 'max':\n",
    "            return max(values)\n",
    "    return None\n",
    "\n",
    "# Apply the aggregation function for Hydraulic Conductivity and Coarse Fraction (case-insensitive)\n",
    "df_svsim['HydraulicConductivity'] = df_svsim['USCS'].apply(lambda x: aggregate_uscs_values(x, hydraulic_conductivity_mapping, agg_func='average'))\n",
    "df_svsim['AverageCoarseFraction'] = df_svsim['USCS'].apply(lambda x: aggregate_uscs_values(x, coarse_fraction_mapping, agg_func='average'))\n",
    "df_svsim['Avg Specific Yield (%)'] = df_svsim['USCS'].apply(lambda x: aggregate_uscs_values(x, specific_yield_mapping, agg_func='average'))\n",
    "df_svsim['Avg Ss (1/L)'] = df_svsim['USCS'].apply(lambda x: aggregate_uscs_values(x, ss_mapping, agg_func='average'))\n",
    "df_svsim['Avg Kv (ft/day)'] = df_svsim['USCS'].apply(lambda x: aggregate_uscs_values(x, kv_mapping, agg_func='average'))\n",
    "\n",
    "# Identify and display any unmatched values\n",
    "unmatched_values = df_svsim[df_svsim['HydraulicConductivity'].isna()]['USCS'].unique()\n",
    "print(\"Unmatched 'USCS' values:\", unmatched_values)\n",
    "\n",
    "# Clean data\n",
    "if 'Unnamed: 0' in df_svsim.columns:\n",
    "    df_svsim = df_svsim.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Convert the 'USCS' column to uppercase\n",
    "df_svsim['USCS'] = df_svsim['USCS'].str.upper()\n",
    "\n",
    "df_svsim.rename(columns={'SVSIM_NAME': 'WCRNUMBER'}, inplace=True)\n",
    "\n",
    "# Get the number of unique values in the 'WCRNUMBER' column\n",
    "unique_wcrnumber_count = df_svsim['WCRNUMBER'].nunique()\n",
    "print(f\"Number of unique WCRNUMBER values: {unique_wcrnumber_count}\")\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "df_svsim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "804e9cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final updated CSV file saved as '11-updated_SVSim.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file = '11-updated_SVSim.csv'\n",
    "df_svsim.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Final updated CSV file saved as '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5aa5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
