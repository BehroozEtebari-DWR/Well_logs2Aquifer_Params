{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import csv files as Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WCRNUMBER</th>\n",
       "      <th>INTERVALSTART</th>\n",
       "      <th>INTERVALEND</th>\n",
       "      <th>SOILCLASSIFICATION</th>\n",
       "      <th>SOILCOLOR</th>\n",
       "      <th>SOILDESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>SW Well-graded SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>SW Well-graded SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>SC Clayey SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>ML Inorganic SILT with low plasticity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SC Clayey SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WCRNUMBER  INTERVALSTART  INTERVALEND  \\\n",
       "0  WCR2019-015573            7.0         10.0   \n",
       "1  WCR2019-015573           10.0         13.0   \n",
       "2  WCR2019-015573           13.0         25.0   \n",
       "3  WCR2019-015573           25.0         26.0   \n",
       "4  WCR2019-015573           26.0         28.0   \n",
       "\n",
       "                      SOILCLASSIFICATION SOILCOLOR SOILDESCRIPTION  \n",
       "0                    SW Well-graded SAND       NaN             NaN  \n",
       "1                    SW Well-graded SAND       NaN             NaN  \n",
       "2                         SC Clayey SAND       NaN             NaN  \n",
       "3  ML Inorganic SILT with low plasticity       NaN             NaN  \n",
       "4                         SC Clayey SAND       NaN             NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# geologiclog_USCS ; released by Ben Brezing on OpenData/OSWCR 09/26/2024\n",
    "df = pd.read_csv(\"geologiclog_uscs.csv\", encoding='utf-8-sig')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text within parentheses\n",
    "def extract_uscs(text):\n",
    "    if isinstance(text, str):\n",
    "        match = re.search(r'\\((.*?)\\)', text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return 'unknown'\n",
    "\n",
    "# Apply the function to the 'SOILCLASSIFICATION' column and create a new 'USCS' column\n",
    "df['USCS'] = df['SOILCLASSIFICATION'].apply(extract_uscs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WCRNUMBER</th>\n",
       "      <th>INTERVALSTART</th>\n",
       "      <th>INTERVALEND</th>\n",
       "      <th>SOILCLASSIFICATION</th>\n",
       "      <th>SOILCOLOR</th>\n",
       "      <th>SOILDESCRIPTION</th>\n",
       "      <th>USCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>SW Well-graded SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>SW Well-graded SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>SC Clayey SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>ML Inorganic SILT with low plasticity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SC Clayey SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WCRNUMBER  INTERVALSTART  INTERVALEND  \\\n",
       "0  WCR2019-015573            7.0         10.0   \n",
       "1  WCR2019-015573           10.0         13.0   \n",
       "2  WCR2019-015573           13.0         25.0   \n",
       "3  WCR2019-015573           25.0         26.0   \n",
       "4  WCR2019-015573           26.0         28.0   \n",
       "\n",
       "                      SOILCLASSIFICATION SOILCOLOR SOILDESCRIPTION     USCS  \n",
       "0                    SW Well-graded SAND       NaN             NaN  unknown  \n",
       "1                    SW Well-graded SAND       NaN             NaN  unknown  \n",
       "2                         SC Clayey SAND       NaN             NaN  unknown  \n",
       "3  ML Inorganic SILT with low plasticity       NaN             NaN  unknown  \n",
       "4                         SC Clayey SAND       NaN             NaN  unknown  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame to verify the new column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of known USCS classifications\n",
    "known_uscs = {\n",
    "    'ML', 'CH', 'CL', 'MH', 'SC', 'SM', 'SP', 'SW', 'GW', 'GP', 'GM', 'GC', 'OH',\n",
    "    'SM-SC', 'SM-ML', 'SM-GP', 'SP-GP', 'SW-GW', 'SC-GC', 'SC-ML', 'SP/GP/CL', 'CL/SP',\n",
    "    'GW-GM', 'OH/CH', 'CL/CH', 'Cl', 'SW-SM', 'SW-SC', 'SP-SM', 'SP-SC', 'OL', 'GW-GC', 'GP-SP',\n",
    "    'GP-GM', 'GP-GC', 'GP-CG', 'CL-ML', 'CH+GP',\n",
    "    # New USCS classifications to be added\n",
    "    'ASH', 'SM-SW', 'ML/GW', 'SP/GP', 'CH/ML', 'CL/ML', 'SC', 'CL/SC', 'SM/SC', 'GP/SP/CL',\n",
    "    'GP/GC', 'SP/SC', 'SP/CH', 'GP/SP', 'CH/SP', 'GP/CL'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map specific soil classifications to USCS or rock categories\n",
    "classification_mapping = {\n",
    "    'Rock - Sedimentary': 'ROCK',\n",
    "    'Rock - Igneous': 'IGNS',\n",
    "    'Rock - Metamorphic': 'META',\n",
    "    'Siltstone': 'STST',\n",
    "    'Sandstone': 'SDST',\n",
    "    \n",
    "    'Bedrock': 'ROCK',\n",
    "    'SILTSTONE/MUDSTONE': 'STST,CLSN',\n",
    "    'Topsoil': 'OH',\n",
    "    'FILL': 'unknown',\n",
    "    'Claystone/hardpan': 'CLSN,ML',\n",
    "    'Siltstone-Claystone': 'STST,CLSN',\n",
    "    'Silty-Sandstone': 'SDST,STST',\n",
    "    'Ishi': 'VOLC',\n",
    "    'Ash': 'ASH',\n",
    "    'Tuff': 'TUFF',\n",
    "    'sltst': 'STST',\n",
    "    'clyst': 'CLSN',\n",
    "    'Mudstone': 'CLSN',\n",
    "    'sltst and clyst': 'STST,CLSN',\n",
    "    'CLAYSTONE/SAND': 'CLSN,SC',\n",
    "    'CLAYSTONE': 'CLSN',\n",
    "    'TUFF or SILTSTONE/CLAYSTONE': 'TUFF,STST,CLSN',\n",
    "    'SILTSTONE/SANDSTONE': 'STST,SDST',\n",
    "    'SIlTSTONE/CLAYSTONE': 'STST,CLSN',\n",
    "    'Sand/Sandstone': 'SDST,SW',\n",
    "    'Volcanic': 'volcanic rock',\n",
    "    'PT PEAT soils with high organic contents': 'PT',\n",
    "    'Claystone/hardpan,': 'CLSN,ML',\n",
    "    'Siltstone-Claystone,': 'STST,CLSN',\n",
    "    'Silty-Sandstone,': 'SDST, ML',\n",
    "    'Basalt': 'BSLT',\n",
    "    'Sltst': 'STST',\n",
    "    'SILTSTONE':'STST',\n",
    "    'SANDSTONE':'SDST',\n",
    "    'Sandstone/Siltstone':'SDST,STST',\n",
    "    'SANDSTONE/SC':'SDST,SC',\n",
    "    'MUDSTONE':'CLSN',\n",
    "    'BASALT':'BSLT',\n",
    "    'CONGLOMERATE':'CONG',\n",
    "    'GP/CH':'GP,CH',\n",
    "    'Claystone':'CLSN',\n",
    "    'CLAYSTONE/MUDSTONE':'CLSN',\n",
    "    'TUFF':'TUFF',\n",
    "    'Top soil':'TPSL',\n",
    "    'SILTSTONE/SANDSTONE,':'STST,SDST',\n",
    "    'SilTSTONE/CLAYSTONE':'STST,CLSN',\n",
    "    'GM/SP':'GM,SP',\n",
    "    'Tuff/ASH':'TUFF, ASH',\n",
    "\n",
    "        # Including the ones with BOM characters manually removed\n",
    "    'ï»¿GC': 'GC',\n",
    "    'ï»¿SP': 'SP',\n",
    "    'ï»¿CL': 'CL',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WCRNUMBER</th>\n",
       "      <th>INTERVALSTART</th>\n",
       "      <th>INTERVALEND</th>\n",
       "      <th>SOILCLASSIFICATION</th>\n",
       "      <th>SOILCOLOR</th>\n",
       "      <th>SOILDESCRIPTION</th>\n",
       "      <th>USCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>SW Well-graded SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>SW Well-graded SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>SC Clayey SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>ML Inorganic SILT with low plasticity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WCR2019-015573</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SC Clayey SAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WCRNUMBER  INTERVALSTART  INTERVALEND  \\\n",
       "0  WCR2019-015573            7.0         10.0   \n",
       "1  WCR2019-015573           10.0         13.0   \n",
       "2  WCR2019-015573           13.0         25.0   \n",
       "3  WCR2019-015573           25.0         26.0   \n",
       "4  WCR2019-015573           26.0         28.0   \n",
       "\n",
       "                      SOILCLASSIFICATION SOILCOLOR SOILDESCRIPTION USCS  \n",
       "0                    SW Well-graded SAND       NaN             NaN   SW  \n",
       "1                    SW Well-graded SAND       NaN             NaN   SW  \n",
       "2                         SC Clayey SAND       NaN             NaN   SC  \n",
       "3  ML Inorganic SILT with low plasticity       NaN             NaN   ML  \n",
       "4                         SC Clayey SAND       NaN             NaN   SC  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract USCS classification\n",
    "def extract_uscs(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip()  # Remove leading/trailing whitespace\n",
    "        # Remove BOM characters if present\n",
    "        text = text.encode('utf-8').decode('utf-8-sig')\n",
    "        # Check for direct USCS classification\n",
    "        for uscs in known_uscs:\n",
    "            if uscs in text.split():\n",
    "                return uscs\n",
    "        # Check for known classifications in the mapping\n",
    "        if text in classification_mapping:\n",
    "            return classification_mapping[text]\n",
    "        # If no direct classification, look for text within parentheses\n",
    "        match = re.search(r'\\((.*?)\\)', text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return 'unknown'\n",
    "\n",
    "# Apply the function to the 'SOILCLASSIFICATION' column and create a new 'USCS' column\n",
    "df['USCS'] = df['SOILCLASSIFICATION'].apply(extract_uscs)\n",
    "\n",
    "# Display the DataFrame to verify the new column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "bad character range /-\\+ at position 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Apply the enhanced function for Hydraulic Conductivity and Coarse Fraction\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHydraulicConductivity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSCS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: aggregate_uscs_values(x, hydraulic_conductivity_mapping, agg_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     66\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverageCoarseFraction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSCS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: aggregate_uscs_values(x, coarse_fraction_mapping, agg_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     67\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Specific Yield (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSCS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: aggregate_uscs_values(x, specific_yield_mapping, agg_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 65\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Apply the enhanced function for Hydraulic Conductivity and Coarse Fraction\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHydraulicConductivity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSCS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: aggregate_uscs_values(x, hydraulic_conductivity_mapping, agg_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     66\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverageCoarseFraction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSCS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: aggregate_uscs_values(x, coarse_fraction_mapping, agg_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     67\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Specific Yield (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSCS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: aggregate_uscs_values(x, specific_yield_mapping, agg_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[8], line 44\u001b[0m, in \u001b[0;36maggregate_uscs_values\u001b[1;34m(uscs_value, mapping, agg_func)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# You can replace None with a default value like 0 or 12 depending on your needs\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Corrected regex: Place the hyphen at the start or end of the character set\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m uscs_list \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms,/-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m+]+\u001b[39m\u001b[38;5;124m'\u001b[39m, uscs_value\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m     46\u001b[0m values \u001b[38;5;241m=\u001b[39m [mapping\u001b[38;5;241m.\u001b[39mget(uscs\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfor\u001b[39;00m uscs \u001b[38;5;129;01min\u001b[39;00m uscs_list \u001b[38;5;28;01mif\u001b[39;00m uscs \u001b[38;5;129;01min\u001b[39;00m mapping]\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Apply 12% coarse fraction if secondary USCS classification is present and missing from mapping\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\re\\__init__.py:206\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(pattern, string, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Split the source string by the occurrences of the pattern,\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m    returning a list containing the resulting substrings.  If\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    capturing parentheses are used in pattern, then the text of all\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m    and the remainder of the string is returned as the final element\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    of the list.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msplit(string, maxsplit)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\re\\__init__.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    293\u001b[0m               \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 294\u001b[0m p \u001b[38;5;241m=\u001b[39m _compiler\u001b[38;5;241m.\u001b[39mcompile(pattern, flags)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\re\\_compiler.py:743\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    742\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 743\u001b[0m     p \u001b[38;5;241m=\u001b[39m _parser\u001b[38;5;241m.\u001b[39mparse(p, flags)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    745\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\re\\_parser.py:982\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    979\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    980\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 982\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    983\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\re\\_parser.py:457\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    455\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    458\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\re\\_parser.py:614\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hi \u001b[38;5;241m<\u001b[39m lo:\n\u001b[0;32m    613\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbad character range \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (this, that)\n\u001b[1;32m--> 614\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(msg, \u001b[38;5;28mlen\u001b[39m(this) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(that))\n\u001b[0;32m    615\u001b[0m     setappend((RANGE, (lo, hi)))\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31merror\u001b[0m: bad character range /-\\+ at position 4"
     ]
    }
   ],
   "source": [
    "# Load the provided Excel file\n",
    "file_path = r'C:\\Users\\betebari\\Documents\\C2VSim_Texture\\OSWCR\\USCS-averageKxy-CoarseFractions.xlsx'\n",
    "excel_data = pd.read_excel(file_path)\n",
    "\n",
    "# Strip any leading/trailing spaces from 'Sediment/Rock Type' column in the Excel data\n",
    "excel_data['Sediment/Rock Type'] = excel_data['Sediment/Rock Type'].str.strip()\n",
    "\n",
    "# Convert 'Sediment/Rock Type' to lowercase for case-insensitive matching\n",
    "excel_data['Sediment/Rock Type'] = excel_data['Sediment/Rock Type'].str.lower()\n",
    "\n",
    "# Create a dictionary mapping Soil Classification to Average Hydraulic Conductivity (case-insensitive)\n",
    "hydraulic_conductivity_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Average Hydraulic Conductivity (ft/day)']))\n",
    "\n",
    "# Create a dictionary mapping Soil Classification to Average Coarse Fraction (case-insensitive)\n",
    "coarse_fraction_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Average Coarse Fraction (%)']))\n",
    "\n",
    "# Strip any leading/trailing spaces from 'USCS' column in the merged DataFrame\n",
    "df['USCS'] = df['USCS'].str.strip()\n",
    "\n",
    "# Remove parentheses from USCS values\n",
    "df['USCS'] = df['USCS'].str.replace(r'[\\(\\)]', '', regex=True)\n",
    "\n",
    "# Convert 'USCS' column to lowercase for case-insensitive matching\n",
    "df['USCS'] = df['USCS'].str.lower()\n",
    "\n",
    "# Create a dictionary mapping Soil Classification to Average Hydraulic Conductivity\n",
    "hydraulic_conductivity_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Average Hydraulic Conductivity (ft/day)']))\n",
    "\n",
    "# Create a dictionary mapping Soil Classification to Average Coarse Fraction\n",
    "coarse_fraction_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Average Coarse Fraction (%)']))\n",
    "\n",
    "# Create separate mappings for Specific Yield, Ss, and Kv based on the Excel data columns\n",
    "specific_yield_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Avg Specific Yield (%)']))\n",
    "ss_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Avg Ss (1/L)']))\n",
    "kv_mapping = dict(zip(excel_data['Sediment/Rock Type'], excel_data['Avg Kv (ft/day)']))\n",
    "\n",
    "# Corrected function to handle more complex USCS combinations\n",
    "def aggregate_uscs_values(uscs_value, mapping, agg_func='average'):\n",
    "    # Handle 'unknown' case by returning None or a default value\n",
    "    if 'unknown' in uscs_value:\n",
    "        return None  # You can replace None with a default value like 0 or 12 depending on your needs\n",
    "\n",
    "    # Corrected regex: Place the hyphen at the start or end of the character set\n",
    "    uscs_list = re.split(r'[\\s,/-\\+]+', uscs_value.lower().strip())\n",
    "    \n",
    "    values = [mapping.get(uscs.strip()) for uscs in uscs_list if uscs in mapping]\n",
    "    \n",
    "    # Apply 12% coarse fraction if secondary USCS classification is present and missing from mapping\n",
    "    if 'gc' in uscs_list or 'sc' in uscs_list or 'gm' in uscs_list or 'sm' in uscs_list:\n",
    "        if agg_func == 'average':\n",
    "            # Assign 12% when no data is found for the given classification\n",
    "            return sum(values) / len(values) if values else 12\n",
    "        elif agg_func == 'max':\n",
    "            return max(values) if values else 12\n",
    "    \n",
    "    if values:\n",
    "        if agg_func == 'average':\n",
    "            return sum(values) / len(values)\n",
    "        elif agg_func == 'max':\n",
    "            return max(values)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Apply the enhanced function for Hydraulic Conductivity and Coarse Fraction\n",
    "df['HydraulicConductivity'] = df['USCS'].apply(lambda x: aggregate_uscs_values(x, hydraulic_conductivity_mapping, agg_func='average'))\n",
    "df['AverageCoarseFraction'] = df['USCS'].apply(lambda x: aggregate_uscs_values(x, coarse_fraction_mapping, agg_func='average'))\n",
    "df['Avg Specific Yield (%)'] = df['USCS'].apply(lambda x: aggregate_uscs_values(x, specific_yield_mapping, agg_func='average'))\n",
    "df['Avg Ss (1/L)'] = df['USCS'].apply(lambda x: aggregate_uscs_values(x, ss_mapping, agg_func='average'))\n",
    "df['Avg Kv (ft/day)'] = df['USCS'].apply(lambda x: aggregate_uscs_values(x, kv_mapping, agg_func='average'))\n",
    "\n",
    "# Check for remaining unmatched values\n",
    "unmatched_values = df[df['HydraulicConductivity'].isna()]['USCS'].unique()\n",
    "print(\"Remaining unmatched 'USCS' values:\", unmatched_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"UPDATED_wellcompletionreports.csv\")\n",
    "# Merge df1 and df2 on 'WCRNUMBER'\n",
    "merged_df = pd.merge(df1, df, on='WCRNUMBER', how='inner')\n",
    "\n",
    "# Drop rows where 'DESCRIPTION' is empty (NaN or empty string)\n",
    "merged_df = merged_df[merged_df['INTERVALSTART'].notna() & (merged_df['INTERVALSTART'] != '')]\n",
    "\n",
    "# Convert the 'USCS' column to uppercase\n",
    "merged_df['USCS'] = merged_df['USCS'].str.upper()\n",
    "\n",
    "# Display the DataFrame\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file = '3-updated_geologiclog_USCS.csv'\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV file saved as '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
