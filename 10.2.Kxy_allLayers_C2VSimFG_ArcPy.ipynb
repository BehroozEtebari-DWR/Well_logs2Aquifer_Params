{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c98a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7f0154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/L1_cum_interpolated_output.csv\n",
      "Dropping columns: ['WellName', 'Well', 'Point', 'X', 'Y', 'Zland', 'INTERVALSTART', 'INTERVALEND', 'Coarse', 'Kxy', 'SY', 'Ss', 'Kv', 'INTERVAL_MIDPOINT', 'INTERVALLENGTH', 'X.1', 'Y.1']\n",
      "Cleaned file saved: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\\L1_cum_interpolated_output.csv\n",
      "Processing file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/L2_cum_interpolated_output.csv\n",
      "Dropping columns: ['WellName', 'Well', 'Point', 'X', 'Y', 'Zland', 'INTERVALSTART', 'INTERVALEND', 'Coarse', 'Kxy', 'SY', 'Ss', 'Kv', 'INTERVAL_MIDPOINT', 'INTERVALLENGTH', 'X.1', 'Y.1']\n",
      "Cleaned file saved: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\\L2_cum_interpolated_output.csv\n",
      "Processing file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/L3_cum_interpolated_output.csv\n",
      "Dropping columns: ['WellName', 'Well', 'Point', 'X', 'Y', 'Zland', 'INTERVALSTART', 'INTERVALEND', 'Coarse', 'Kxy', 'SY', 'Ss', 'Kv', 'INTERVAL_MIDPOINT', 'INTERVALLENGTH', 'X.1', 'Y.1']\n",
      "Cleaned file saved: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\\L3_cum_interpolated_output.csv\n",
      "Processing file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/L4_cum_interpolated_output.csv\n",
      "Dropping columns: ['WellName', 'Well', 'Point', 'X', 'Y', 'Zland', 'INTERVALSTART', 'INTERVALEND', 'Coarse', 'Kxy', 'SY', 'Ss', 'Kv', 'INTERVAL_MIDPOINT', 'INTERVALLENGTH', 'X.1', 'Y.1']\n",
      "Cleaned file saved: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\\L4_cum_interpolated_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing the CSV files\n",
    "input_dir = \"C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/\"\n",
    "\n",
    "# List of files to process\n",
    "files_to_process = [\n",
    "    \"L1_cum_interpolated_output.csv\",\n",
    "    \"L2_cum_interpolated_output.csv\",\n",
    "    \"L3_cum_interpolated_output.csv\",\n",
    "    \"L4_cum_interpolated_output.csv\",\n",
    "]\n",
    "\n",
    "# Columns to drop while processing\n",
    "columns_to_drop = [\n",
    "    'WellName', 'Well', 'Point', 'X', 'Y', 'Zland', 'INTERVALSTART', 'INTERVALEND',\n",
    "    'Coarse', 'Kxy', 'SY', 'Ss', 'Kv', 'INTERVAL_MIDPOINT', 'INTERVALLENGTH','X.1', 'Y.1',\n",
    "]\n",
    "\n",
    "# Directory to save cleaned files\n",
    "cleaned_dir = os.path.join(input_dir, \"cleaned_files\")\n",
    "os.makedirs(cleaned_dir, exist_ok=True)\n",
    "\n",
    "# Process each file to drop columns\n",
    "for file_name in files_to_process:\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Load the file\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    layer_df = pd.read_csv(file_path, low_memory=False)\n",
    "    \n",
    "    # Drop the specified columns if they exist\n",
    "    columns_present = [col for col in columns_to_drop if col in layer_df.columns]\n",
    "    print(f\"Dropping columns: {columns_present}\")\n",
    "    layer_df = layer_df.drop(columns=columns_present)\n",
    "\n",
    "    # Save the cleaned file\n",
    "    cleaned_file_path = os.path.join(cleaned_dir, file_name)\n",
    "    layer_df.to_csv(cleaned_file_path, index=False)\n",
    "    print(f\"Cleaned file saved: {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c207f276-231e-464d-9bc0-7f3ad17af943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cleaned file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\\L1_cum_interpolated_output.csv\n",
      "Processing cleaned file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\\L2_cum_interpolated_output.csv\n",
      "Processing cleaned file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\\L3_cum_interpolated_output.csv\n",
      "Processing cleaned file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\\L4_cum_interpolated_output.csv\n",
      "Combined DataFrame saved to: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/Combined_Cumulative_Layers.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine the cleaned files into a single DataFrame\n",
    "\n",
    "# Path to the directory containing the cleaned files\n",
    "cleaned_dir = \"C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/cleaned_files\"\n",
    "\n",
    "# Initialize an empty DataFrame for the combined result\n",
    "combined_df = None\n",
    "\n",
    "# Process each cleaned file\n",
    "for file_name in files_to_process:\n",
    "    cleaned_file_path = os.path.join(cleaned_dir, file_name)\n",
    "    \n",
    "    if not os.path.exists(cleaned_file_path):\n",
    "        print(f\"File not found: {cleaned_file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Load the cleaned file\n",
    "    print(f\"Processing cleaned file: {cleaned_file_path}\")\n",
    "    layer_df = pd.read_csv(cleaned_file_path, low_memory=False)\n",
    "\n",
    "    # Rename 'RASTERVALU' column to the current layer\n",
    "    layer_name = file_name.split('_')[0]  # Extract layer name (e.g., 'L1', 'L2', etc.)\n",
    "    layer_df = layer_df.rename(columns={'RASTERVALU': layer_name})\n",
    "    \n",
    "    # Merge with the combined DataFrame\n",
    "    if combined_df is None:\n",
    "        combined_df = layer_df[['OBJECTID', layer_name]]  # Initialize with the first file's data\n",
    "    else:\n",
    "        combined_df = pd.merge(combined_df, layer_df[['OBJECTID', layer_name]], on=['OBJECTID'], how='inner')\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "output_file = os.path.join(input_dir, \"Combined_Cumulative_Layers.csv\")\n",
    "if combined_df is not None:\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined DataFrame saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"No valid data processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bec1c82-cb21-477c-8966-e39bf5a598ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/L1_cum_interpolated_output.csv\n",
      "Reading file: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/Combined_Cumulative_Layers.csv\n",
      "Concatenating DataFrames column-wise...\n",
      "Updated file saved to: C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/Updated_Filtered_WCRs_AEM.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing the CSV files\n",
    "input_dir = \"C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/\"\n",
    "\n",
    "# Files to concatenate\n",
    "filtered_file = os.path.join(input_dir, \"L1_cum_interpolated_output.csv\")\n",
    "combined_file = os.path.join(input_dir, \"Combined_Cumulative_Layers.csv\")\n",
    "\n",
    "# Output file path\n",
    "output_file = os.path.join(input_dir, \"Updated_Filtered_WCRs_AEM.csv\")\n",
    "\n",
    "# Check if the files exist\n",
    "if not os.path.exists(filtered_file):\n",
    "    raise FileNotFoundError(f\"Filtered file not found: {filtered_file}\")\n",
    "if not os.path.exists(combined_file):\n",
    "    raise FileNotFoundError(f\"Combined file not found: {combined_file}\")\n",
    "\n",
    "# Read the CSV files\n",
    "print(f\"Reading file: {filtered_file}\")\n",
    "filtered_df = pd.read_csv(filtered_file, low_memory=False)\n",
    "\n",
    "print(f\"Reading file: {combined_file}\")\n",
    "combined_df = pd.read_csv(combined_file, low_memory=False)\n",
    "\n",
    "# Ensure the files have the same number of rows\n",
    "if len(filtered_df) != len(combined_df):\n",
    "    raise ValueError(\"The two files have a different number of rows. Cannot concatenate column-wise.\")\n",
    "\n",
    "# Concatenate the two DataFrames column-wise\n",
    "print(\"Concatenating DataFrames column-wise...\")\n",
    "updated_df = pd.concat([filtered_df, combined_df], axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new file\n",
    "updated_df.to_csv(output_file, index=False)\n",
    "print(f\"Updated file saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5022b2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WellName</th>\n",
       "      <th>Well</th>\n",
       "      <th>Point</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Zland</th>\n",
       "      <th>INTERVALSTART</th>\n",
       "      <th>INTERVALEND</th>\n",
       "      <th>Coarse</th>\n",
       "      <th>Kxy</th>\n",
       "      <th>SY</th>\n",
       "      <th>Ss</th>\n",
       "      <th>Kv</th>\n",
       "      <th>INTERVAL_MIDPOINT</th>\n",
       "      <th>INTERVALLENGTH</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WCR2024-000122</td>\n",
       "      <td>308698</td>\n",
       "      <td>1</td>\n",
       "      <td>665784.728675</td>\n",
       "      <td>4.109370e+06</td>\n",
       "      <td>740.8212179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>27.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>150.549377</td>\n",
       "      <td>2694.378174</td>\n",
       "      <td>2742.664551</td>\n",
       "      <td>3472.556885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WCR2024-000122</td>\n",
       "      <td>308698</td>\n",
       "      <td>2</td>\n",
       "      <td>665784.728675</td>\n",
       "      <td>4.109370e+06</td>\n",
       "      <td>740.8212179</td>\n",
       "      <td>55.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>56.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>150.549377</td>\n",
       "      <td>2694.378174</td>\n",
       "      <td>2742.664551</td>\n",
       "      <td>3472.556885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WCR2024-000122</td>\n",
       "      <td>308698</td>\n",
       "      <td>3</td>\n",
       "      <td>665784.728675</td>\n",
       "      <td>4.109370e+06</td>\n",
       "      <td>740.8212179</td>\n",
       "      <td>57.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>150.549377</td>\n",
       "      <td>2694.378174</td>\n",
       "      <td>2742.664551</td>\n",
       "      <td>3472.556885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WCR2024-000122</td>\n",
       "      <td>308698</td>\n",
       "      <td>4</td>\n",
       "      <td>665784.728675</td>\n",
       "      <td>4.109370e+06</td>\n",
       "      <td>740.8212179</td>\n",
       "      <td>63.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>69.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>150.549377</td>\n",
       "      <td>2694.378174</td>\n",
       "      <td>2742.664551</td>\n",
       "      <td>3472.556885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WCR2024-000122</td>\n",
       "      <td>308698</td>\n",
       "      <td>5</td>\n",
       "      <td>665784.728675</td>\n",
       "      <td>4.109370e+06</td>\n",
       "      <td>740.8212179</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>76.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>150.549377</td>\n",
       "      <td>2694.378174</td>\n",
       "      <td>2742.664551</td>\n",
       "      <td>3472.556885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         WellName    Well  Point              X             Y        Zland  \\\n",
       "0  WCR2024-000122  308698      1  665784.728675  4.109370e+06  740.8212179   \n",
       "1  WCR2024-000122  308698      2  665784.728675  4.109370e+06  740.8212179   \n",
       "2  WCR2024-000122  308698      3  665784.728675  4.109370e+06  740.8212179   \n",
       "3  WCR2024-000122  308698      4  665784.728675  4.109370e+06  740.8212179   \n",
       "4  WCR2024-000122  308698      5  665784.728675  4.109370e+06  740.8212179   \n",
       "\n",
       "   INTERVALSTART  INTERVALEND  Coarse        Kxy    SY       Ss       Kv  \\\n",
       "0            0.0         55.0    12.0  12.000000  12.0  12.0000  12.0000   \n",
       "1           55.0         57.0     5.0   0.016402   3.0   0.0025   0.0005   \n",
       "2           57.0         63.0     5.0   0.016402   3.0   0.0025   0.0005   \n",
       "3           63.0         75.0     5.0   0.016402   3.0   0.0025   0.0005   \n",
       "4           75.0         77.0     5.0   0.016402   3.0   0.0025   0.0005   \n",
       "\n",
       "   INTERVAL_MIDPOINT  INTERVALLENGTH          L1           L2           L3  \\\n",
       "0               27.5            55.0  150.549377  2694.378174  2742.664551   \n",
       "1               56.0           112.0  150.549377  2694.378174  2742.664551   \n",
       "2               60.0           120.0  150.549377  2694.378174  2742.664551   \n",
       "3               69.0           138.0  150.549377  2694.378174  2742.664551   \n",
       "4               76.0           152.0  150.549377  2694.378174  2742.664551   \n",
       "\n",
       "            L4  \n",
       "0  3472.556885  \n",
       "1  3472.556885  \n",
       "2  3472.556885  \n",
       "3  3472.556885  \n",
       "4  3472.556885  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "        'RASTERVALU', 'X.1', 'Y.1', 'OBJECTID'\n",
    "]\n",
    "\n",
    "# Drop specified columns\n",
    "updated_df = updated_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Display the first few rows\n",
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc86d3b-158e-47a0-b6e9-8b4f42e110da",
   "metadata": {},
   "source": [
    "# IntervalEND > = Layer base's C2VSimFG , select the data and save selected as a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d2b9ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: L1\n",
      "Statistics for 'Kxy' in L1:\n",
      "count    5.095101e+06\n",
      "mean     2.238967e+01\n",
      "std      3.731831e+01\n",
      "min      1.431496e-07\n",
      "25%      1.361523e-01\n",
      "50%      2.472949e+00\n",
      "75%      1.911594e+01\n",
      "max      2.500000e+02\n",
      "Name: Kxy, dtype: float64\n",
      "First few rows of the DataFrame for L1:\n",
      "        WellName  Well  Point              X             Y            Zland  \\\n",
      "347403         1     1     51  713861.829177  4.107089e+06  103.36000330752   \n",
      "2224612        1     1     71  819457.149950  3.899480e+06  927.58002968256   \n",
      "4805721        1     1     25  620122.947435  4.320000e+06   52.11000166752   \n",
      "7535827        1     1      1  578943.523506  4.395457e+06   172.4000055168   \n",
      "4805722        1     1     26  620122.947435  4.320000e+06   52.11000166752   \n",
      "\n",
      "         INTERVALSTART  INTERVALEND  Coarse     Kxy  ...  INTERVALLENGTH  \\\n",
      "347403             0.0     3.000000     8.0  0.0001  ...        3.000000   \n",
      "2224612            0.0    25.000001     5.0  0.0001  ...       25.000001   \n",
      "4805721            0.0     0.500000    45.0  0.0001  ...        0.500000   \n",
      "7535827            0.0    16.400001     5.0  0.0001  ...       16.400001   \n",
      "4805722            0.5    10.000000    15.0  0.0001  ...       10.500000   \n",
      "\n",
      "                 L1          L2           L3           L4  MultiplyCoarse  \\\n",
      "347403   206.372345  711.345215  1113.734985  2491.280762       24.000001   \n",
      "2224612  751.053101  927.076477   975.605103  1000.551208      125.000004   \n",
      "4805721  410.114105  747.695190  1468.430908  1519.005127       22.500001   \n",
      "7535827  336.029480  670.320496  1238.928101  1674.717407       82.000003   \n",
      "4805722  410.114105  747.695190  1468.430908  1519.005127      157.500005   \n",
      "\n",
      "         MultiplyKxy  MultiplyKv  MultiplySy  MultiplySs  \n",
      "347403       0.00030     0.00150   22.500001    0.151500  \n",
      "2224612      0.00250     0.01250   75.000002    0.062500  \n",
      "4805721      0.00005     0.02500    7.000000    0.000253  \n",
      "7535827      0.00164     0.00820   49.200002    0.041000  \n",
      "4805722      0.00105     0.00525  210.000007    0.053025  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Processing layer: L2\n",
      "Statistics for 'Kxy' in L2:\n",
      "count    1.888640e+06\n",
      "mean     2.046992e+01\n",
      "std      3.581563e+01\n",
      "min      1.431496e-07\n",
      "25%      1.361523e-01\n",
      "50%      1.614830e+00\n",
      "75%      1.510803e+01\n",
      "max      2.500000e+02\n",
      "Name: Kxy, dtype: float64\n",
      "First few rows of the DataFrame for L2:\n",
      "        WellName  Well  Point              X             Y           Zland  \\\n",
      "7535840        1     1     14  578943.523506  4.395457e+06  172.4000055168   \n",
      "7535841        1     1     15  578943.523506  4.395457e+06  172.4000055168   \n",
      "7535842        1     1     16  578943.523506  4.395457e+06  172.4000055168   \n",
      "7535843        1     1     17  578943.523506  4.395457e+06  172.4000055168   \n",
      "7535844        1     1     18  578943.523506  4.395457e+06  172.4000055168   \n",
      "\n",
      "         INTERVALSTART  INTERVALEND  Coarse     Kxy  ...  INTERVALLENGTH  \\\n",
      "7535840     449.360014   488.720016    90.0  0.0001  ...      938.080030   \n",
      "7535841     488.720016   570.720018     5.0  0.0001  ...     1059.440034   \n",
      "7535842     570.720018   574.000018    90.0  0.0001  ...     1144.720037   \n",
      "7535843     574.000018   669.120021     5.0  0.0001  ...     1243.120040   \n",
      "7535844     669.120021   670.320496    90.0  0.0001  ...     1367.760044   \n",
      "\n",
      "                L1          L2           L3           L4  MultiplyCoarse  \\\n",
      "7535840  336.02948  670.320496  1238.928101  1674.717407    84427.202702   \n",
      "7535841  336.02948  670.320496  1238.928101  1674.717407     5297.200170   \n",
      "7535842  336.02948  670.320496  1238.928101  1674.717407   103024.803297   \n",
      "7535843  336.02948  670.320496  1238.928101  1674.717407     6215.600199   \n",
      "7535844  336.02948  670.320496  1238.928101  1674.717407   123098.403939   \n",
      "\n",
      "         MultiplyKxy  MultiplyKv    MultiplySy  MultiplySs  \n",
      "7535840     0.093808  469.040015  17823.520570    0.047373  \n",
      "7535841     0.105944    0.529720   3178.320102    2.648600  \n",
      "7535842     0.114472  572.360018  21749.680696    0.057808  \n",
      "7535843     0.124312    0.621560   3729.360119    3.107800  \n",
      "7535844     0.136776  683.880022  25987.440832    0.069072  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Processing layer: L3\n",
      "Statistics for 'Kxy' in L3:\n",
      "count    5.132590e+05\n",
      "mean     1.338890e+01\n",
      "std      2.970324e+01\n",
      "min      1.431496e-07\n",
      "25%      1.361523e-01\n",
      "50%      1.361523e-01\n",
      "75%      1.380333e+01\n",
      "max      2.500000e+02\n",
      "Name: Kxy, dtype: float64\n",
      "First few rows of the DataFrame for L3:\n",
      "        WellName   Well  Point              X             Y  \\\n",
      "2255420    10056  10030     12  820781.580838  4.065784e+06   \n",
      "1852969    10071  10045      7  800910.162596  4.082171e+06   \n",
      "1849511    10072  10046     12  800495.833418  4.081557e+06   \n",
      "766155     10083  10057     39  740406.153000  4.003619e+06   \n",
      "766156     10083  10057     40  740406.153000  4.003619e+06   \n",
      "\n",
      "                     Zland  INTERVALSTART  INTERVALEND  Coarse     Kxy  ...  \\\n",
      "2255420     416.5500133296     198.000006   205.930099    10.0  0.0001  ...   \n",
      "1852969    409.71001311072     220.000007   255.632782    32.5  0.0001  ...   \n",
      "1849511    402.78001288896     240.000008   251.952972    32.5  0.0001  ...   \n",
      "766155   643.6169205301239    1180.000038  1210.000039    32.5  0.0001  ...   \n",
      "766156   643.6169205301239    1210.000039  1340.000043     5.0  0.0001  ...   \n",
      "\n",
      "         INTERVALLENGTH          L1           L2           L3           L4  \\\n",
      "2255420      458.000015  105.649071   157.602478   205.930099   255.930099   \n",
      "1852969      480.000015  157.442352   207.558609   255.632782   305.632782   \n",
      "1849511      500.000016  155.328781   205.344543   251.952972   301.952972   \n",
      "766155      2390.000076  652.121460  1176.205444  1485.964722  1535.780029   \n",
      "766156      2550.000082  652.121460  1176.205444  1485.964722  1535.780029   \n",
      "\n",
      "         MultiplyCoarse  MultiplyKxy  MultiplyKv    MultiplySy  MultiplySs  \n",
      "2255420     4580.000147       0.0458    0.000046     41.220001    0.000458  \n",
      "1852969    15600.000499       0.0480  120.120004   7920.000253    0.720120  \n",
      "1849511    16250.000520       0.0500  125.125004   8250.000264    0.750125  \n",
      "766155     77675.002486       0.2390  598.097519  39435.001262    3.585598  \n",
      "766156     12750.000408       0.2550    1.275000   7650.000245    6.375000  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Processing layer: L4\n",
      "Statistics for 'Kxy' in L4:\n",
      "count    9.629700e+04\n",
      "mean     9.502468e+00\n",
      "std      2.559559e+01\n",
      "min      1.431496e-07\n",
      "25%      1.361523e-01\n",
      "50%      1.361523e-01\n",
      "75%      2.360088e+00\n",
      "max      2.500000e+02\n",
      "Name: Kxy, dtype: float64\n",
      "First few rows of the DataFrame for L4:\n",
      "        WellName   Well  Point              X             Y  \\\n",
      "6520226    10004   9978     18  723959.916934  4.177149e+06   \n",
      "6520227    10004   9978     19  723959.916934  4.177149e+06   \n",
      "1852970    10071  10045      8  800910.162596  4.082171e+06   \n",
      "1852971    10071  10045      9  800910.162596  4.082171e+06   \n",
      "1849512    10072  10046     13  800495.833418  4.081557e+06   \n",
      "\n",
      "                     Zland  INTERVALSTART  INTERVALEND  Coarse     Kxy  ...  \\\n",
      "6520226  765.6200244998399     239.000008   241.000008     NaN  0.0001  ...   \n",
      "6520227  765.6200244998399     241.000008   286.779266    15.0  0.0001  ...   \n",
      "1852970    409.71001311072     260.000008   280.000009    32.5  0.0001  ...   \n",
      "1852971    409.71001311072     280.000009   305.632782    40.0  0.0001  ...   \n",
      "1849512    402.78001288896     260.000008   301.952972     5.0  0.0001  ...   \n",
      "\n",
      "         INTERVALLENGTH          L1          L2          L3          L4  \\\n",
      "6520226      480.000015  136.803970  186.781342  236.779266  286.779266   \n",
      "6520227     1030.000033  136.803970  186.781342  236.779266  286.779266   \n",
      "1852970      540.000017  157.442352  207.558609  255.632782  305.632782   \n",
      "1852971      590.000019  157.442352  207.558609  255.632782  305.632782   \n",
      "1849512      575.000018  155.328781  205.344543  251.952972  301.952972   \n",
      "\n",
      "         MultiplyCoarse  MultiplyKxy  MultiplyKv    MultiplySy  MultiplySs  \n",
      "6520226             NaN       0.0480         NaN           NaN         NaN  \n",
      "6520227    15450.000494       0.1030    0.000103   3090.000099    0.001030  \n",
      "1852970    17550.000562       0.0540  135.135004   8910.000285    0.810135  \n",
      "1852971    23600.000755       0.0590  147.502106  16815.000538    0.162545  \n",
      "1849512     2875.000092       0.0575    0.287500   1725.000055    1.437500  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of cumulative layers\n",
    "layers = ['L1', 'L2', 'L3', 'L4']\n",
    "\n",
    "# Directory to save the output files\n",
    "output_dir = \"C:/Users/betebari/Documents/C2VSim_Texture/Aq-Params/Grouped_Results/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize dictionaries to store data for each layer and grouped results\n",
    "layer_dataframes = {}\n",
    "grouped_results = {}\n",
    "\n",
    "# Track previously processed rows to exclude them\n",
    "previous_rows = pd.Series([False] * len(updated_df))\n",
    "\n",
    "def process_group(group, layer_column):\n",
    "    \"\"\"Apply logic to adjust INTERVALEND based on the current layer depth.\"\"\"\n",
    "    last_interval_end = group.iloc[-1]['INTERVALEND']\n",
    "    depth_for_layer = group.iloc[-1][layer_column]\n",
    "\n",
    "    if last_interval_end >= depth_for_layer:\n",
    "        group.at[group.index[-1], 'INTERVALEND'] = depth_for_layer\n",
    "    elif depth_for_layer >= 0.75 * last_interval_end:\n",
    "        group = None\n",
    "    return group\n",
    "\n",
    "# Process each layer\n",
    "for layer in layers:\n",
    "    print(f\"Processing layer: {layer}\")\n",
    "\n",
    "    # Step 1: Filter rows for the current layer, excluding previously processed rows\n",
    "    current_layer_rows = (updated_df['INTERVALSTART'] <= updated_df[layer]) & ~previous_rows\n",
    "    layer_df = updated_df[current_layer_rows]\n",
    "\n",
    "    # Step 2: Sort the DataFrame by 'WellName' and 'INTERVALSTART'\n",
    "    layer_df = layer_df.sort_values(by=['WellName', 'INTERVALSTART'])\n",
    "\n",
    "    # Step 3: Replace -9999.0 in the 'Kxy' column with 0.0001 and handle NaN values\n",
    "    layer_df['Kxy'] = layer_df['Kxy'].replace(-9999.0, 0.0001).fillna(0.0001)\n",
    "\n",
    "    # Step 4: Add calculated columns\n",
    "    layer_df['MultiplyCoarse'] = layer_df['INTERVALLENGTH'] * layer_df['Coarse']\n",
    "    layer_df['MultiplyKxy'] = layer_df['INTERVALLENGTH'] * layer_df['Kxy']\n",
    "    layer_df['MultiplyKv'] = layer_df['INTERVALLENGTH'] * layer_df['Kv']\n",
    "    layer_df['MultiplySy'] = layer_df['INTERVALLENGTH'] * layer_df['SY']\n",
    "    layer_df['MultiplySs'] = layer_df['INTERVALLENGTH'] * layer_df['Ss']\n",
    "\n",
    "    # Debugging: Check statistics for `Kxy`\n",
    "    print(f\"Statistics for 'Kxy' in {layer}:\")\n",
    "    print(layer_df['Kxy'].describe())\n",
    "\n",
    "    # Step 5: Apply group-specific logic\n",
    "    filtered_groups = []\n",
    "    for _, group in layer_df.groupby('WellName'):\n",
    "        processed_group = process_group(group, layer)\n",
    "        if processed_group is not None:\n",
    "            filtered_groups.append(processed_group)\n",
    "\n",
    "    # Combine the filtered groups back into a DataFrame\n",
    "    layer_dataframes[layer] = pd.concat(filtered_groups) if filtered_groups else pd.DataFrame()\n",
    "\n",
    "    # Update `previous_rows` to include the rows processed in this layer\n",
    "    previous_rows = previous_rows | current_layer_rows\n",
    "\n",
    "    # Display the first few rows of the processed DataFrame\n",
    "    print(f\"First few rows of the DataFrame for {layer}:\")\n",
    "    print(layer_dataframes[layer].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9948c3-513d-40b8-83f8-1b1c763f862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing grouped operations for L1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betebari\\AppData\\Local\\Temp\\ipykernel_15848\\3069489447.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_df = layer_df.groupby(['WellName', 'X', 'Y']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped results for L1:\n",
      "  WellName              X             Y  Avg_Coarse  Avg_Kxy    Avg_Kv  \\\n",
      "0        1  578943.523506  4.395457e+06   49.345973   0.0001  0.230451   \n",
      "1        1  620122.947435  4.320000e+06   42.388978   0.0001  0.176190   \n",
      "2        1  713861.829177  4.107089e+06   35.072852   0.0001  0.182915   \n",
      "3        1  819457.149950  3.899480e+06   30.757834   0.0001  0.234428   \n",
      "4       10  587088.229224  4.280778e+06   37.165659   0.0001  0.203169   \n",
      "\n",
      "     Avg_Ss     Avg_Sy  \n",
      "0  0.001553  10.847443  \n",
      "1  0.001235  17.056492  \n",
      "2  0.001195  13.817648  \n",
      "3  0.001564  15.644755  \n",
      "4  0.001576  11.186811  \n",
      "Processing grouped operations for L2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betebari\\AppData\\Local\\Temp\\ipykernel_15848\\3069489447.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_df = layer_df.groupby(['WellName', 'X', 'Y']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped results for L2:\n",
      "  WellName              X             Y  Avg_Coarse  Avg_Kxy    Avg_Kv  \\\n",
      "0        1  578943.523506  4.395457e+06   55.980616   0.0001  0.300086   \n",
      "1    10002  764899.120947  4.105654e+06   13.841682   0.0001  0.068814   \n",
      "2    10004  608454.874527  4.193323e+06   36.575095   0.0001  0.002518   \n",
      "3    10005  608453.614092  4.193312e+06   17.200000   0.0001  0.023642   \n",
      "4    10005  764473.781381  4.052965e+06   29.267875   0.0001  0.220896   \n",
      "\n",
      "     Avg_Ss     Avg_Sy  \n",
      "0  0.001031  12.596351  \n",
      "1  0.002012   8.798748  \n",
      "2  0.003618  11.691065  \n",
      "3  0.000365  17.776364  \n",
      "4  0.001618  14.913320  \n",
      "Processing grouped operations for L3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betebari\\AppData\\Local\\Temp\\ipykernel_15848\\3069489447.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_df = layer_df.groupby(['WellName', 'X', 'Y']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped results for L3:\n",
      "  WellName              X             Y  Avg_Coarse  Avg_Kxy        Avg_Kv  \\\n",
      "0    10056  820781.580838  4.065784e+06   10.000000   0.0001  1.000000e-07   \n",
      "1    10071  800910.162596  4.082171e+06   32.500000   0.0001  2.502500e-01   \n",
      "2    10072  800495.833418  4.081557e+06   32.500000   0.0001  2.502500e-01   \n",
      "3    10083  740406.153000  4.003619e+06    9.107812   0.0001  3.780641e-02   \n",
      "4    10098  781237.370694  4.090744e+06   32.291667   0.0001  2.483580e-01   \n",
      "\n",
      "     Avg_Ss     Avg_Sy  \n",
      "0  0.000001   0.090000  \n",
      "1  0.001500  16.500000  \n",
      "2  0.001500  16.500000  \n",
      "3  0.002351   5.016563  \n",
      "4  0.001508  16.397727  \n",
      "Processing grouped operations for L4...\n"
     ]
    }
   ],
   "source": [
    "# Compute averages for each parameter in each layer\n",
    "for layer in layers:\n",
    "    print(f\"Processing grouped operations for {layer}...\")\n",
    "\n",
    "    # Access the processed DataFrame for the current layer\n",
    "    layer_df = layer_dataframes[layer]\n",
    "\n",
    "    # Ensure valid data for 'Multiply' and 'Interval_Length'\n",
    "    if 'MultiplyCoarse' not in layer_df.columns or 'INTERVALLENGTH' not in layer_df.columns:\n",
    "        raise ValueError(f\"'Multiply' or 'Interval_Length' column is missing in {layer}\")\n",
    "\n",
    "    # Ensure required columns exist for each parameter\n",
    "    for col in ['Coarse','Kxy','Kv', 'Ss', 'SY']:\n",
    "        if col not in layer_df.columns:\n",
    "            layer_df[col] = 0  # Assign a default value if the column is missing\n",
    "\n",
    "    # Compute averages for each parameter using distinct logic\n",
    "    grouped_df = layer_df.groupby(['WellName', 'X', 'Y']).apply(\n",
    "        lambda group: pd.Series({\n",
    "            'Avg_Coarse': group['MultiplyCoarse'].sum() / group['INTERVALLENGTH'].sum(),\n",
    "            'Avg_Kxy': group['MultiplyKxy'].sum() / group['INTERVALLENGTH'].sum(),\n",
    "            'Avg_Kv': group['MultiplyKv'].sum() / group['INTERVALLENGTH'].sum(),\n",
    "            'Avg_Ss': group['MultiplySs'].sum() / group['INTERVALLENGTH'].sum(),\n",
    "            'Avg_Sy': group['MultiplySy'].sum() / group['INTERVALLENGTH'].sum(),\n",
    "        })\n",
    "    ).reset_index()\n",
    "\n",
    "    # Store the grouped result\n",
    "    grouped_results[layer] = grouped_df\n",
    "\n",
    "    # Display the first few rows of the results\n",
    "    print(f\"Grouped results for {layer}:\")\n",
    "    print(grouped_df.head())\n",
    "\n",
    "# Save the grouped results to CSV files\n",
    "for layer, grouped_df in grouped_results.items():\n",
    "    output_file = os.path.join(output_dir, f\"Grouped_Averages_{layer}.csv\")\n",
    "    grouped_df.to_csv(output_file, index=False)\n",
    "    print(f\"Grouped averages for {layer} saved to: {output_file}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fe8ca-2767-4c5b-a427-dc10fecad1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
